{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis with RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6w3ETtszQ2V"
      },
      "source": [
        "## **In this practice session, we will learn how to implement Recurrent Neural Networks for Sentiment Analysis**\n",
        "## **We will use imdb reviews dataset that is available in the Keras library for the implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXQdoQtl2W8s"
      },
      "source": [
        "### **Data processing**\n",
        "  *   Import the required libraries from Keras\n",
        "  *   Load the IMDB reviews dataset from Keras library\n",
        "  *   Load one instance of the review and sentiment\n",
        "  *   Pad the input data to make all input information into the same length\n",
        "\n",
        "### **Build an RNN model**\n",
        "  *   Construct a simple LSTM model \n",
        "  *   Compile the model and fit the data into the model\n",
        "  *   Evaluate the model on unseen test data\n",
        "  *   Make model predictions on test data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyyD8zH-4aF0"
      },
      "source": [
        "## **Importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv_Ig056m44W"
      },
      "source": [
        "#import the required libraries for the implementation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.preprocessing import sequence\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p3Mjnh64d0B"
      },
      "source": [
        "## **Load the data from Keras into train and test variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da3mdAicnvht"
      },
      "source": [
        "#load the imdb dataset into train and test set\n",
        "from keras.datasets import imdb\n",
        "vocabulary_size = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXhvH7LD4m6Q"
      },
      "source": [
        "## **Print one instance of the review and corresponding sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_GILIwBqINi",
        "outputId": "b22245a6-4845-4ad1-ce50-ee27503d9b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#understanding how the dataset looks like\n",
        "words = imdb.get_word_index()\n",
        "#the words are already vectorized in the dataset, hence we reverse the process to see the word distribution\n",
        "vects = {i: word for word, i in words.items()}\n",
        "print('review')\n",
        "print([vects.get(i, ' ') for i in X_train[6]])\n",
        "#the sentiment is 1 if the review is positive and 0 if the review is negative\n",
        "print('sentiment')\n",
        "print(y_train[6])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review\n",
            "['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
            "sentiment\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUfJwZ4j4shL"
      },
      "source": [
        "## **Pad the data sequence to make the inputs into same length**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od_HvaisqL_v"
      },
      "source": [
        "#for the RNN to work all our input dependencies must have same length \n",
        "total_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=total_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=total_words)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPAN7UzT4yEU"
      },
      "source": [
        "## **Build a basic LSTM model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JeymMMLqQlp",
        "outputId": "1aac62d9-af29-4557-e5ec-867d67124f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#we will build a simple LSTM model with one embedding layer, one LSTM and one output layer\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJOZxFUh412i"
      },
      "source": [
        "## **Compile the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjFLKJRsqSJO"
      },
      "source": [
        "#compile the model by passing the optimizer and loss function and the evaluation metric\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBMcurgh44iV"
      },
      "source": [
        "## **Pass required parameters and fit the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kshIa4whqUSp",
        "outputId": "a56836fb-03f6-418d-b71c-88041566c732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#fit the data to the model and begin training\n",
        "batch_size = 128\n",
        "num_epochs = 5\n",
        "x_val, y_val = X_train[:batch_size], y_train[:batch_size]\n",
        "xtrain, ytrain = X_train[batch_size:], y_train[batch_size:]\n",
        "model.fit(xtrain, ytrain, validation_data=(x_val, y_val), batch_size=batch_size, epochs=num_epochs)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "195/195 [==============================] - 197s 1s/step - loss: 0.5655 - accuracy: 0.6971 - val_loss: 0.3411 - val_accuracy: 0.8828\n",
            "Epoch 2/5\n",
            "195/195 [==============================] - 193s 990ms/step - loss: 0.2934 - accuracy: 0.8816 - val_loss: 0.3611 - val_accuracy: 0.8359\n",
            "Epoch 3/5\n",
            "195/195 [==============================] - 193s 990ms/step - loss: 0.2453 - accuracy: 0.9057 - val_loss: 0.2606 - val_accuracy: 0.8828\n",
            "Epoch 4/5\n",
            "195/195 [==============================] - 193s 991ms/step - loss: 0.2135 - accuracy: 0.9197 - val_loss: 0.2353 - val_accuracy: 0.9062\n",
            "Epoch 5/5\n",
            "195/195 [==============================] - 192s 986ms/step - loss: 0.1961 - accuracy: 0.9265 - val_loss: 0.3018 - val_accuracy: 0.8672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7211a8780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTeBZOeV5m9Z"
      },
      "source": [
        "## **Evaluate the model on test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfuN-xZ9qWs6",
        "outputId": "9339d7ee-c98f-430f-bd53-ed8efcd55f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#evaluate the model accuracy on unseen test data\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8600800037384033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ze29pbz5vGs"
      },
      "source": [
        "## **Make model predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkdQIC9lqZ1F",
        "outputId": "ed283b5f-80f1-479c-826f-749f238efaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#make model predictions on test data\n",
        "print(\"Prediction: \",model.predict_classes(X_test[1:10]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:  [[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjuQQqINxtqf",
        "outputId": "9a96604d-39e1-4d1e-dcfc-cc9b87f81d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#compare the model prediction with actual data\n",
        "print(\"Actual: \",y_test[1:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual:  [1 1 0 1 1 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTobFVtpzPfY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}